{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSPCom-KmApV"
   },
   "source": [
    "# Complex Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iAve6DCL4JH4"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['training_d']>\n",
      "<KeysViewHDF5 ['train_labels_d']>\n"
     ]
    }
   ],
   "source": [
    "# X training\n",
    "f = h5py.File(\"./X_training_serial_balanced.h5\",\"r\")\n",
    "print(f.keys())\n",
    "train_images = f['training_d'][:].astype('float32')\n",
    "f.close()\n",
    "train_images[np.isnan(train_images)] = 0.\n",
    "\n",
    "# Y training\n",
    "f = h5py.File(\"./Y_training_serial_balanced.h5\",\"r\")\n",
    "print(f.keys())\n",
    "train_labels = f['train_labels_d'][:].astype(int)\n",
    "f.close()\n",
    "\n",
    "# X validation\n",
    "f = h5py.File(\"./X_validation.h5\",\"r\")\n",
    "val_images = f['validation'][:]\n",
    "f.close()\n",
    "val_images[np.isnan(val_images)] = 0.\n",
    "\n",
    "# Y validation\n",
    "f = h5py.File(\"./Y_validation.h5\",\"r\")\n",
    "val_labels = f['val_labels'][:].astype(int)\n",
    "f.close()\n",
    "\n",
    "# X testing\n",
    "f = h5py.File(\"./X_testing.h5\",\"r\")\n",
    "test_images = f['testing'][:]\n",
    "f.close()\n",
    "test_images[np.isnan(test_images)] = 0.\n",
    "\n",
    "# Y testing\n",
    "f = h5py.File(\"./Y_testing.h5\",\"r\")\n",
    "test_labels = f['test_labels'][:].astype(int)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22540 22540 22540 22540 22540]\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "# Number of occurences of each class that occur before\n",
    "a = np.unique(train_labels,return_counts =1, return_index=1, return_inverse = 1)\n",
    "print(a[3])\n",
    "\n",
    "print(train_labels[3:13])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024730772\n",
      "<class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "print(train_images[0][16][16][0])\n",
    "print(type(train_images[0][16][16][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRFxccghyMVo"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "L9YmGQBQPrdn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 16, 16, 32)        416       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 64)          8256      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 64)          16448     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 30,245\n",
      "Trainable params: 30,245\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Simple CNN Network\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, kernel_size = (2, 2), strides = (2,2), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.Conv2D(64, kernel_size = (2, 2), strides = (2,2), activation='relu'))\n",
    "model.add(layers.Conv2D(64, kernel_size = (2, 2), strides = (2,2), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(learning_rate=0.01),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MdDzI75PUXrG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "14088/14088 [==============================] - 43s 3ms/step - loss: 1.5851 - accuracy: 0.2578 - val_loss: 1.6051 - val_accuracy: 0.2928\n",
      "Epoch 2/20\n",
      "14088/14088 [==============================] - 39s 3ms/step - loss: 1.5587 - accuracy: 0.2880 - val_loss: 1.7338 - val_accuracy: 0.2289\n",
      "Epoch 3/20\n",
      "14088/14088 [==============================] - 40s 3ms/step - loss: 1.5393 - accuracy: 0.3049 - val_loss: 1.6596 - val_accuracy: 0.2906\n",
      "Epoch 4/20\n",
      "14088/14088 [==============================] - 38s 3ms/step - loss: 1.5243 - accuracy: 0.3138 - val_loss: 1.8121 - val_accuracy: 0.1861\n",
      "Epoch 5/20\n",
      "14088/14088 [==============================] - 38s 3ms/step - loss: 1.5115 - accuracy: 0.3215 - val_loss: 1.8338 - val_accuracy: 0.1850\n",
      "Epoch 6/20\n",
      "14088/14088 [==============================] - 40s 3ms/step - loss: 1.5011 - accuracy: 0.3301 - val_loss: 1.7628 - val_accuracy: 0.2233\n",
      "Epoch 7/20\n",
      "14088/14088 [==============================] - 41s 3ms/step - loss: 1.4929 - accuracy: 0.3343 - val_loss: 1.8528 - val_accuracy: 0.1972\n",
      "Epoch 8/20\n",
      "14088/14088 [==============================] - 39s 3ms/step - loss: 1.4857 - accuracy: 0.3382 - val_loss: 1.8046 - val_accuracy: 0.2311\n",
      "Epoch 9/20\n",
      "14088/14088 [==============================] - 39s 3ms/step - loss: 1.4796 - accuracy: 0.3419 - val_loss: 1.9429 - val_accuracy: 0.1939\n",
      "Epoch 10/20\n",
      "14088/14088 [==============================] - 41s 3ms/step - loss: 1.4744 - accuracy: 0.3455 - val_loss: 1.8109 - val_accuracy: 0.2289\n",
      "Epoch 11/20\n",
      "14088/14088 [==============================] - 40s 3ms/step - loss: 1.4688 - accuracy: 0.3486 - val_loss: 1.8664 - val_accuracy: 0.2033\n",
      "Epoch 12/20\n",
      "14088/14088 [==============================] - 40s 3ms/step - loss: 1.4636 - accuracy: 0.3523 - val_loss: 1.8885 - val_accuracy: 0.2044\n",
      "Epoch 13/20\n",
      "14088/14088 [==============================] - 39s 3ms/step - loss: 1.4597 - accuracy: 0.3561 - val_loss: 2.0025 - val_accuracy: 0.1728\n",
      "Epoch 14/20\n",
      "14088/14088 [==============================] - 38s 3ms/step - loss: 1.4550 - accuracy: 0.3582 - val_loss: 1.7929 - val_accuracy: 0.2472\n",
      "Epoch 15/20\n",
      "14088/14088 [==============================] - 45s 3ms/step - loss: 1.4503 - accuracy: 0.3621 - val_loss: 1.8729 - val_accuracy: 0.2161\n",
      "Epoch 16/20\n",
      "14088/14088 [==============================] - 38s 3ms/step - loss: 1.4462 - accuracy: 0.3631 - val_loss: 1.9462 - val_accuracy: 0.1894\n",
      "Epoch 17/20\n",
      "14088/14088 [==============================] - 37s 3ms/step - loss: 1.4419 - accuracy: 0.3660 - val_loss: 1.9414 - val_accuracy: 0.1967\n",
      "Epoch 18/20\n",
      "14088/14088 [==============================] - 38s 3ms/step - loss: 1.4381 - accuracy: 0.3689 - val_loss: 1.9387 - val_accuracy: 0.1972\n",
      "Epoch 19/20\n",
      "14088/14088 [==============================] - 38s 3ms/step - loss: 1.4345 - accuracy: 0.3702 - val_loss: 1.9428 - val_accuracy: 0.2022\n",
      "Epoch 20/20\n",
      "14088/14088 [==============================] - 39s 3ms/step - loss: 1.4306 - accuracy: 0.3723 - val_loss: 2.0541 - val_accuracy: 0.1711\n",
      "\n",
      "\n",
      "[0 3 3 1 3 4 3 0 2 0 3 1 0 3 3 1 1 0 2 1 0 0 1 1 3 3 3 2 0 1 2 0 0 3 3 1 0\n",
      " 3 2 0]\n",
      "\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "57/57 - 0s - loss: 1.7745 - accuracy: 0.2522\n",
      "\n",
      "\n",
      "0.2522222101688385\n",
      "\n",
      "\n",
      "[0 1 2 3 4]\n",
      "[392 332 219 644 213]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=20, batch_size = 8,\n",
    "                    validation_data=(val_images, val_labels), shuffle=True)\n",
    "\n",
    "print(\"\\n\")\n",
    "# Predict on the test images\n",
    "predictions = model.predict(test_images)\n",
    "# Print our model's predictions.\n",
    "predicts = np.argmax(predictions, axis=1)\n",
    "print(predicts[0:40]) \n",
    "print(\"\\n\")\n",
    "# Check our predictions against the ground truths.\n",
    "print(test_labels[0:40].flatten())\n",
    "\n",
    "print(\"\\n\")\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "print(\"\\n\")\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(test_acc)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Number of occurences of each class that occur before\n",
    "b = np.unique(predicts,return_counts =1, return_index=1, return_inverse = 1)\n",
    "print(b[0])\n",
    "print(b[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"model_arch_9.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Alkinoos\\anaconda3\\envs\\Project\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\Alkinoos\\anaconda3\\envs\\Project\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Alkinoos\\AppData\\Local\\Temp\\tmp0cwakvhc\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39440"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFLite Section\n",
    "\n",
    "\n",
    "tflite_model_name = 'MFCC_9'\n",
    "# Convert Keras model to a tflite model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# Convert the model to the TensorFlow Lite format with quantization\n",
    "quantize = True\n",
    "if (quantize):\n",
    "    def representative_dataset():\n",
    "        for i in range(500):\n",
    "            yield([train_images[i].reshape(1,32,32,3).astype('float32')])\n",
    "    # Set the optimization flag.\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    # Enforce full-int8 quantization\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "    converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "    # Provide a representative dataset to ensure we quantize correctly.\n",
    "converter.representative_dataset = representative_dataset\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "open(tflite_model_name + '.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Alkinoos\\AppData\\Local\\Temp\\tmpjoav1uhu\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Alkinoos\\AppData\\Local\\Temp\\tmpjoav1uhu\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39440"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFLite Section\n",
    "\n",
    "\n",
    "tflite_model_name = 'quant_model_9'\n",
    "# Convert Keras model to a tflite model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# Convert the model to the TensorFlow Lite format with quantization\n",
    "quantize = True\n",
    "if (quantize):\n",
    "    def representative_dataset():\n",
    "        for i in range(500):\n",
    "            yield([train_images[i].reshape(1,32,32,3).astype('float32')])\n",
    "    # Set the optimization flag.\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    # Enforce full-int8 quantization\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "    converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "    # Provide a representative dataset to ensure we quantize correctly.\n",
    "converter.representative_dataset = representative_dataset\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "open(tflite_model_name + '.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Input details ==\n",
      "name: conv2d_input\n",
      "shape: [ 1 32 32  3]\n",
      "type: <class 'numpy.int8'>\n",
      "\n",
      "== Output details ==\n",
      "name: Identity\n",
      "shape: [1 5]\n",
      "type: <class 'numpy.int8'>\n"
     ]
    }
   ],
   "source": [
    "# This function here takes in the model and outputs a header file we will import into the TFLite example project folder. (/Core/Inc/)\n",
    "# Function: Convert some hex value into an array for C programming\n",
    "\n",
    "def hex_to_c_array(hex_data, var_name):\n",
    "\n",
    "    c_str = ''\n",
    "\n",
    "    # Create header guard\n",
    "    c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
    "    c_str += '#define ' + var_name.upper() + '_H\\n\\n'\n",
    "\n",
    "    # Add array length at top of file\n",
    "    c_str += '\\nunsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
    "\n",
    "    # Declare C variable\n",
    "    c_str += 'unsigned char ' + var_name + '[] = {'\n",
    "    hex_array = []\n",
    "    for i, val in enumerate(hex_data) :\n",
    "\n",
    "        # Construct string from hex\n",
    "        hex_str = format(val, '#04x')\n",
    "\n",
    "        # Add formatting so each line stays within 80 characters\n",
    "        if (i + 1) < len(hex_data):\n",
    "            hex_str += ','\n",
    "        if (i + 1) % 12 == 0:\n",
    "            hex_str += '\\n '\n",
    "        hex_array.append(hex_str)\n",
    "\n",
    "    # Add closing brace\n",
    "    c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n",
    "\n",
    "    # Close out header guard\n",
    "    c_str += '#endif //' + var_name.upper() + '_H'\n",
    "\n",
    "    return c_str\n",
    "\n",
    "\n",
    "c_model_name = 'MFCC_9'\n",
    "# Write TFLite model to a C source (or header) file\n",
    "with open(c_model_name + '.h', 'w') as file:\n",
    "    file.write(hex_to_c_array(tflite_model, c_model_name))\n",
    "    \n",
    "\n",
    "tflite_interpreter = tf.lite.Interpreter(model_path=tflite_model_name + '.tflite')\n",
    "tflite_interpreter.allocate_tensors()\n",
    "input_details = tflite_interpreter.get_input_details()\n",
    "output_details = tflite_interpreter.get_output_details()\n",
    "\n",
    "print(\"== Input details ==\")\n",
    "print(\"name:\", input_details[0]['name'])\n",
    "print(\"shape:\", input_details[0]['shape'])\n",
    "print(\"type:\", input_details[0]['dtype'])\n",
    "\n",
    "print(\"\\n== Output details ==\")\n",
    "print(\"name:\", output_details[0]['name'])\n",
    "print(\"shape:\", output_details[0]['shape'])\n",
    "print(\"type:\", output_details[0]['dtype'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cnn.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
