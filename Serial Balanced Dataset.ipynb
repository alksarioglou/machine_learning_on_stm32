{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "# For splitting the dataset to training and validation tests\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "\n",
    "# X training\n",
    "f = h5py.File(\"./../X_training.h5\",\"r\")\n",
    "train_images = f['training'][:]\n",
    "f.close()\n",
    "train_images[np.isnan(train_images)] = 0.\n",
    "\n",
    "# Y training\n",
    "f = h5py.File(\"./../Y_training.h5\",\"r\")\n",
    "train_labels = f['train_labels'][:].astype(int)\n",
    "f.close()\n",
    "train_labels = train_labels.flatten()\n",
    "\n",
    "# X validation\n",
    "f = h5py.File(\"./../X_validation.h5\",\"r\")\n",
    "val_images = f['validation'][:]\n",
    "f.close()\n",
    "val_images[np.isnan(val_images)] = 0.\n",
    "\n",
    "# Y validation\n",
    "f = h5py.File(\"./../Y_validation.h5\",\"r\")\n",
    "val_labels = f['val_labels'][:].astype(int)\n",
    "f.close()\n",
    "val_labels = val_labels.flatten()\n",
    "\n",
    "# X testing\n",
    "f = h5py.File(\"./../X_validation.h5\",\"r\")\n",
    "test_images = f['validation'][:]\n",
    "f.close()\n",
    "test_images[np.isnan(test_images)] = 0.\n",
    "\n",
    "# Y testing\n",
    "f = h5py.File(\"./../Y_validation.h5\",\"r\")\n",
    "test_labels = f['val_labels'][:].astype(int)\n",
    "f.close()\n",
    "test_labels = test_labels.flatten()\n",
    "\n",
    "\n",
    "class_names = ['Rest', 'MI Left Fist', 'MI Right Fist', 'MI Both Fists', 'MI Both Feet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X testing\n",
    "f = h5py.File(\"./../X_validation.h5\",\"r\")\n",
    "test_images = f['validation'][:]\n",
    "f.close()\n",
    "test_images[np.isnan(test_images)] = 0.\n",
    "\n",
    "# Y testing\n",
    "f = h5py.File(\"./../Y_validation.h5\",\"r\")\n",
    "test_labels = f['val_labels'][:].astype(int)\n",
    "f.close()\n",
    "test_labels = test_labels.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4.]\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros(50)\n",
    "\n",
    "a[0:10] = 0\n",
    "a[10:20] = 1\n",
    "a[20:30] = 2\n",
    "a[30:40] = 3\n",
    "a[40:50] = 4\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 1)\n",
      "(230, 1)\n",
      "(220, 1)\n",
      "(210, 1)\n",
      "(240, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class_0_ind = np.argwhere(test_labels == 0)\n",
    "\n",
    "print(class_0_ind.shape)\n",
    "\n",
    "class_1_ind = np.argwhere(test_labels == 1)\n",
    "\n",
    "print(class_1_ind.shape)\n",
    "\n",
    "class_2_ind = np.argwhere(test_labels == 2)\n",
    "\n",
    "print(class_2_ind.shape)\n",
    "\n",
    "class_3_ind = np.argwhere(test_labels == 3)\n",
    "\n",
    "print(class_3_ind.shape)\n",
    "\n",
    "class_4_ind = np.argwhere(test_labels == 4)\n",
    "\n",
    "print(class_4_ind.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "(900, 32, 32, 3)\n",
      "(900, 1)\n"
     ]
    }
   ],
   "source": [
    "# Separate images and labels of Class 0\n",
    "class_0_im = np.zeros((900,32,32,3))\n",
    "class_0_lab = np.zeros((900,1))\n",
    "n=0\n",
    "for ind in class_0_ind:\n",
    "    class_0_im[n] = test_images[ind]\n",
    "    class_0_lab[n] = test_labels[ind]\n",
    "    n=n+1\n",
    "\n",
    "print(\"Done.\")\n",
    "print(class_0_im.shape)\n",
    "print(class_0_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "(230, 32, 32, 3)\n",
      "(230, 1)\n"
     ]
    }
   ],
   "source": [
    "# Separate images and labels of Class 1\n",
    "class_1_im = np.zeros((230,32,32,3))\n",
    "class_1_lab = np.zeros((230,1))\n",
    "n=0\n",
    "for ind in class_1_ind:\n",
    "    class_1_im[n] = test_images[ind]\n",
    "    class_1_lab[n] = test_labels[ind]\n",
    "    n=n+1\n",
    "\n",
    "print(\"Done.\")\n",
    "print(class_1_im.shape)\n",
    "print(class_1_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "(220, 32, 32, 3)\n",
      "(220, 1)\n"
     ]
    }
   ],
   "source": [
    "# Separate images and labels of Class 2\n",
    "class_2_im = np.zeros((220,32,32,3))\n",
    "class_2_lab = np.zeros((220,1))\n",
    "n=0\n",
    "for ind in class_2_ind:\n",
    "    class_2_im[n] = test_images[ind]\n",
    "    class_2_lab[n] = test_labels[ind]\n",
    "    n=n+1\n",
    "\n",
    "print(\"Done.\")\n",
    "print(class_2_im.shape)\n",
    "print(class_2_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "(210, 32, 32, 3)\n",
      "(210, 1)\n"
     ]
    }
   ],
   "source": [
    "# Separate images and labels of Class 3\n",
    "class_3_im = np.zeros((210,32,32,3))\n",
    "class_3_lab = np.zeros((210,1))\n",
    "n=0\n",
    "for ind in class_3_ind:\n",
    "    class_3_im[n] = test_images[ind]\n",
    "    class_3_lab[n] = test_labels[ind]\n",
    "    n=n+1\n",
    "\n",
    "print(\"Done.\")\n",
    "print(class_3_im.shape)\n",
    "print(class_3_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "(240, 32, 32, 3)\n",
      "(240, 1)\n"
     ]
    }
   ],
   "source": [
    "# Separate images and labels of Class 4\n",
    "class_4_im = np.zeros((240,32,32,3))\n",
    "class_4_lab = np.zeros((240,1))\n",
    "n=0\n",
    "for ind in class_4_ind:\n",
    "    class_4_im[n] = test_images[ind]\n",
    "    class_4_lab[n] = test_labels[ind]\n",
    "    n=n+1\n",
    "\n",
    "print(\"Done.\")\n",
    "print(class_4_im.shape)\n",
    "print(class_4_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_balanced = np.zeros((1050,32,32,3))\n",
    "train_labels_balanced = np.zeros((1050,1))\n",
    "n=0\n",
    "\n",
    "# For images\n",
    "for i in range(0,1050,50):\n",
    "    train_images_balanced[i:i+10]    = class_0_im[n:n+10] # Class 0\n",
    "    train_images_balanced[i+10:i+20] = class_1_im[n:n+10] # Class 1\n",
    "    train_images_balanced[i+20:i+30] = class_2_im[n:n+10] # Class 2\n",
    "    train_images_balanced[i+30:i+40] = class_3_im[n:n+10] # Class 3\n",
    "    train_images_balanced[i+40:i+50] = class_4_im[n:n+10] # Class 4\n",
    "    n = n+10\n",
    "\n",
    "k=0\n",
    "# For labels\n",
    "for i in range(0,1050,50):\n",
    "    train_labels_balanced[i:i+10]    = class_0_lab[k:k+10] # Class 0\n",
    "    train_labels_balanced[i+10:i+20] = class_1_lab[k:k+10] # Class 1\n",
    "    train_labels_balanced[i+20:i+30] = class_2_lab[k:k+10] # Class 2\n",
    "    train_labels_balanced[i+30:i+40] = class_3_lab[k:k+10] # Class 3\n",
    "    train_labels_balanced[i+40:i+50] = class_4_lab[k:k+10] # Class 4\n",
    "    k = k+10\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1050, 32, 32, 3)\n",
      "(1050, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_images_balanced.shape)\n",
    "print(train_labels_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels_balanced[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced Dataset\n",
    "f = h5py.File(\"X_validation_serial_balanced.h5\",\"w\")\n",
    "training_dset = f.create_dataset('training_d', data = train_images_balanced, compression=\"gzip\", compression_opts=0)\n",
    "\n",
    "# Training downsampled labels\n",
    "f = h5py.File(\"Y_validation_serial_balanced.h5\",\"w\")\n",
    "traininglbs_dset = f.create_dataset('train_labels_d', data = train_labels_balanced, compression=\"gzip\", compression_opts=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1050, 32, 32, 3)\n",
      "(1050, 1)\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]]\n"
     ]
    }
   ],
   "source": [
    "# Read labels and images\n",
    "h5f = h5py.File('X_validation_serial_balanced.h5','r')\n",
    "images = h5f['training_d'][:]\n",
    "h5f.close()\n",
    "\n",
    "h5f = h5py.File('Y_validation_serial_balanced.h5','r')\n",
    "labels = h5f['train_labels_d'][:]\n",
    "h5f.close()\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "print(labels[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183600, 32, 32, 3)\n",
      "(183600,)\n",
      "(1800, 32, 32, 3)\n",
      "(1800,)\n",
      "(1800, 32, 32, 3)\n",
      "(1800,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "print(val_images.shape)\n",
    "print(val_labels.shape)\n",
    "\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]]\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]]\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "print(train_images[0])\n",
    "print(test_images[0])\n",
    "print(val_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 3. 3. 3.]\n",
      "[0. 0. 0. ... 3. 3. 3.]\n",
      "[0. 0. 0. ... 4. 4. 4.]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels)\n",
    "print(test_labels)\n",
    "print(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the input array\n",
    "train_images2 = train_images.reshape((3600,1,32,32,3))\n",
    "val_images2 = val_images.reshape((1800,1,32,32,3))\n",
    "test_images2 = test_images.reshape((1800,1,32,32,3))\n",
    "\n",
    "train_labels2 = train_labels[0::1]\n",
    "val_labels2 = val_labels[0::1]\n",
    "test_labels2 = test_labels[0::1]\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(train_images2,train_labels2,random_state=82, test_size=1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 1, 32, 32, 3)\n",
      "(1800,)\n",
      "[0. 1. 0. 0. 0. 1. 2. 0. 3. 0. 0. 4. 0. 0. 1. 2. 4. 0. 0. 3.]\n",
      "[0. 2. 0. 3. 0. 3. 0. 0. 3. 0. 1. 2. 2. 4. 0. 3. 2. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(test_labels.shape)\n",
    "\n",
    "print(train_labels[0:20])\n",
    "print(test_labels[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 30, 30, 32)\n",
      "(None, 1, 15, 15, 32)\n",
      "(None, 1, 13, 13, 64)\n",
      "(None, 1, 6, 6, 64)\n",
      "(None, 1, 4, 4, 64)\n",
      "(None, 1, 1024)\n",
      "(None, 128)\n",
      "(None, 5)\n",
      "(None, 5)\n"
     ]
    }
   ],
   "source": [
    "# MODEL EFFORT 4: Time distributed Layers\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(TimeDistributed(layers.Conv2D(32, (3, 3), activation='relu'), input_shape=(32, 32, 3)))\n",
    "print(model.output_shape)\n",
    "model.add(TimeDistributed(layers.MaxPooling2D((2, 2))))\n",
    "print(model.output_shape)\n",
    "#model.add(TimeDistributed(layers.Conv2D(32, (3, 3), activation='relu')))\n",
    "#print(model.output_shape)\n",
    "model.add(TimeDistributed(layers.Conv2D(64, (3, 3), activation='relu')))\n",
    "print(model.output_shape)\n",
    "model.add(TimeDistributed(layers.MaxPooling2D((2, 2))))\n",
    "print(model.output_shape)\n",
    "model.add(TimeDistributed(layers.Conv2D(64, (3, 3), activation='relu')))\n",
    "print(model.output_shape)\n",
    "#model.add(TimeDistributed(layers.MaxPooling2D((2, 2))))\n",
    "#print(model.output_shape)\n",
    "#model.add(TimeDistributed(layers.Conv2D(128, (3, 3), activation='relu')))\n",
    "#print(model.output_shape)\n",
    "#model.add(TimeDistributed(layers.MaxPooling2D(2, 2)))\n",
    "#print(model.output_shape)\n",
    "#model.add(TimeDistributed(layers.Conv2D(256, (3, 3), activation='relu')))\n",
    "#print(model.output_shape)\n",
    "\n",
    "# FLatten Layer\n",
    "#model.add(TimeDistributed(layers.ReLU()))\n",
    "#print(model.output_shape)\n",
    "#model.add(TimeDistributed(layers.MaxPooling2D(2, 2)))\n",
    "#print(model.output_shape)\n",
    "model.add(TimeDistributed(layers.Flatten()))\n",
    "print(model.output_shape)\n",
    "\n",
    "# LSTM Layer\n",
    "model.add(layers.LSTM(128))\n",
    "print(model.output_shape)\n",
    "# Dense Layer\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "print(model.output_shape)\n",
    "model.add(layers.Softmax())\n",
    "print(model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_36 (TimeDis (None, 1, 30, 30, 32)     896       \n",
      "_________________________________________________________________\n",
      "time_distributed_37 (TimeDis (None, 1, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_38 (TimeDis (None, 1, 13, 13, 64)     18496     \n",
      "_________________________________________________________________\n",
      "time_distributed_39 (TimeDis (None, 1, 6, 6, 64)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_40 (TimeDis (None, 1, 4, 4, 64)       36928     \n",
      "_________________________________________________________________\n",
      "time_distributed_41 (TimeDis (None, 1, 1024)           0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 128)               590336    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "softmax_6 (Softmax)          (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 671,749\n",
      "Trainable params: 671,749\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 8s 4ms/step - loss: 1.6010 - accuracy: 0.4853 - val_loss: 1.5912 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=(SGD(lr=0.001)),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=train_images2, y=train_labels2, batch_size=2, epochs=1, \n",
    "                    validation_data=(test_images2, test_labels2),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 - 0s - loss: 1.5912 - accuracy: 0.5000\n",
      "0.5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Accuracy on validation data\n",
    "val_loss, val_acc = model.evaluate(val_images2,  val_labels2, verbose=2)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 - 0s - loss: 1.5912 - accuracy: 0.5000\n",
      "0.5\n",
      "1.5911566019058228\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on test data\n",
    "test_loss, test_acc = model.evaluate(test_images2,  test_labels2, verbose=2)\n",
    "print(test_acc)\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800,)\n",
      "[0]\n",
      "[0. 2. 0. ... 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test images\n",
    "predictions = model.predict(test_images2)\n",
    "\n",
    "# Print our model's predictions.\n",
    "a = np.argmax(predictions, axis=1)\n",
    "print(a.shape)\n",
    "print(np.unique(a))\n",
    "#print(np.argmax(predictions, axis=1)) \n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-74b7a262d874>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloaded_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Alkinoos\\anaconda3\\envs\\Labs_best\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    180\u001b[0m     if (h5py is not None and (\n\u001b[0;32m    181\u001b[0m         isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[1;32m--> 182\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Alkinoos\\anaconda3\\envs\\Labs_best\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No model found in config file.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     model = model_config_lib.model_from_config(model_config,\n\u001b[0;32m    178\u001b[0m                                                custom_objects=custom_objects)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "loaded_model = models.load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Alkinoos\\anaconda3\\envs\\Labs_best\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\Alkinoos\\anaconda3\\envs\\Labs_best\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Alkinoos\\AppData\\Local\\Temp\\tmpvi70k58g\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8048"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFLite Section\n",
    "\n",
    "\n",
    "tflite_model_name = 'MFCC'\n",
    "# Convert Keras model to a tflite model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# Convert the model to the TensorFlow Lite format with quantization\n",
    "quantize = True\n",
    "if (quantize):\n",
    "    def representative_dataset():\n",
    "        for i in range(500):\n",
    "            yield([train_images[i].reshape(1,32,32,3)])\n",
    "    # Set the optimization flag.\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    # Enforce full-int8 quantization\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "    converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "    # Provide a representative dataset to ensure we quantize correctly.\n",
    "converter.representative_dataset = representative_dataset\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "open(tflite_model_name + '.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function here takes in the model and outputs a header file we will import into the TFLite example project folder. (/Core/Inc/)\n",
    "# Function: Convert some hex value into an array for C programming\n",
    "\n",
    "def hex_to_c_array(hex_data, var_name):\n",
    "\n",
    "    c_str = ''\n",
    "\n",
    "    # Create header guard\n",
    "    c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
    "    c_str += '#define ' + var_name.upper() + '_H\\n\\n'\n",
    "\n",
    "    # Add array length at top of file\n",
    "    c_str += '\\nunsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
    "\n",
    "    # Declare C variable\n",
    "    c_str += 'unsigned char ' + var_name + '[] = {'\n",
    "    hex_array = []\n",
    "    for i, val in enumerate(hex_data) :\n",
    "\n",
    "        # Construct string from hex\n",
    "        hex_str = format(val, '#04x')\n",
    "\n",
    "        # Add formatting so each line stays within 80 characters\n",
    "        if (i + 1) < len(hex_data):\n",
    "            hex_str += ','\n",
    "        if (i + 1) % 12 == 0:\n",
    "            hex_str += '\\n '\n",
    "        hex_array.append(hex_str)\n",
    "\n",
    "    # Add closing brace\n",
    "    c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n",
    "\n",
    "    # Close out header guard\n",
    "    c_str += '#endif //' + var_name.upper() + '_H'\n",
    "\n",
    "    return c_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_model_name = 'MFCC'\n",
    "# Write TFLite model to a C source (or header) file\n",
    "with open(c_model_name + '.h', 'w') as file:\n",
    "    file.write(hex_to_c_array(tflite_model, c_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Input details ==\n",
      "name: conv2d_input\n",
      "shape: [ 1 32 32  3]\n",
      "type: <class 'numpy.int8'>\n",
      "\n",
      "== Output details ==\n",
      "name: Identity\n",
      "shape: [1 5]\n",
      "type: <class 'numpy.int8'>\n"
     ]
    }
   ],
   "source": [
    "tflite_interpreter = tf.lite.Interpreter(model_path=tflite_model_name + '.tflite')\n",
    "tflite_interpreter.allocate_tensors()\n",
    "input_details = tflite_interpreter.get_input_details()\n",
    "output_details = tflite_interpreter.get_output_details()\n",
    "\n",
    "print(\"== Input details ==\")\n",
    "print(\"name:\", input_details[0]['name'])\n",
    "print(\"shape:\", input_details[0]['shape'])\n",
    "print(\"type:\", input_details[0]['dtype'])\n",
    "\n",
    "print(\"\\n== Output details ==\")\n",
    "print(\"name:\", output_details[0]['name'])\n",
    "print(\"shape:\", output_details[0]['shape'])\n",
    "print(\"type:\", output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance of network\n",
    "\n",
    "predictions = np.zeros((len(test_images),), dtype=int)\n",
    "input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
    "for i in range(len(test_images)):\n",
    "    val_batch = test_images[i]\n",
    "    #We must convert the data into int8 format before invoking inference.\n",
    "    val_batch = val_batch / input_scale + input_zero_point\n",
    "    val_batch = np.expand_dims(val_batch, axis=0).astype(input_details[0][\"dtype\"])\n",
    "    tflite_interpreter.set_tensor(input_details[0]['index'], val_batch)\n",
    "    tflite_interpreter.allocate_tensors()\n",
    "    tflite_interpreter.invoke()\n",
    "\n",
    "    tflite_model_predictions = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
    "    #print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
    "    output = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
    "    predictions[i] = output.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of quantized to int8 model is 900.0%\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for i in range(len(predictions)):\n",
    "    if (predictions[i] == test_labels[i]):\n",
    "        sum = sum + 1\n",
    "accuracy_score = sum / 100\n",
    "print(\"Accuracy of quantized to int8 model is {}%\".format(accuracy_score*100))\n",
    "#print(\"Compared to float32 accuracy of {}%\".format(score[1]*100))\n",
    "#print(\"We have a change of {}%\".format((accuracy_score-score[1])*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
